{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 12:45:15.924998: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-03 12:45:15.948725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 12:45:16.401882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Read data from CSV files\n",
    "notes_df = pd.read_csv('/home/admin1/Desktop/LSTM/csv_dataset/notes.csv')\n",
    "test_df = pd.read_csv('/home/admin1/Desktop/LSTM/csv_dataset/testset.csv')\n",
    "\n",
    "# Extract data and labels from the test set\n",
    "data_test = test_df[['x_test', 'future']].to_numpy()\n",
    "x_test_string = data_test[:, 0]\n",
    "y_test_string = data_test[:, 1]\n",
    "\n",
    "# Convert string representations to lists\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in x_test_string:\n",
    "    # Remove square brackets and newline characters\n",
    "    i = i.strip('[]\\n')\n",
    "    # Split the string and convert elements to integers\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "    # Remove square brackets and newline characters\n",
    "    i = i.strip('[]\\n')\n",
    "    # Split the string and convert elements to integers\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Create a dictionary of unique notes\n",
    "notes_ = notes_df.iloc[:, 0].to_numpy()\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, data , data_labels):\n",
    "        self.data = data\n",
    "        self.data_labels = data_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx] , self.data_labels[idx]\n",
    "\n",
    "\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('embedding.weight', tensor([[ 0.7544,  0.3040,  1.6204,  ...,  1.0693,  0.3593,  1.7222],\n",
      "        [-0.6374,  2.1065,  0.2349,  ...,  0.1555, -1.1250, -1.3722],\n",
      "        [ 0.9668,  0.8912,  0.6208,  ..., -0.1869, -0.0127, -1.1430],\n",
      "        ...,\n",
      "        [ 0.3607, -0.6401, -0.3260,  ..., -0.2234, -1.3026,  0.3360],\n",
      "        [-0.5505,  0.0945,  0.1333,  ..., -1.0991,  1.2944, -0.4325],\n",
      "        [-0.8061,  1.4256, -1.8271,  ..., -1.4185, -0.7938, -0.5755]])), ('lstm.weight_ih_l0', tensor([[-0.5117, -0.2418,  0.2535,  ...,  0.0728, -0.6606, -0.0609],\n",
      "        [ 0.1960,  0.2230, -0.2698,  ...,  0.3531,  0.2382, -0.2042],\n",
      "        [-0.0205,  0.1092, -0.1290,  ...,  0.1861,  0.2731,  0.3246],\n",
      "        ...,\n",
      "        [-0.3047, -0.0027, -0.0142,  ..., -0.3275, -0.1612,  0.4778],\n",
      "        [ 0.2551,  0.1787, -0.3990,  ..., -0.2909,  0.3369, -0.6293],\n",
      "        [ 0.2171, -0.1421,  0.3830,  ..., -0.2837, -0.5508,  0.4782]])), ('lstm.weight_hh_l0', tensor([[ 0.1808, -0.0802, -0.3100,  ...,  0.3902, -0.1617,  0.2618],\n",
      "        [-0.0244,  0.8830, -0.1458,  ..., -0.3285,  0.1276,  1.0595],\n",
      "        [ 0.0616, -0.5989, -0.1576,  ...,  0.0447, -0.0295, -0.2083],\n",
      "        ...,\n",
      "        [ 0.5930, -0.0425,  0.3712,  ...,  0.3310,  0.7363,  0.0599],\n",
      "        [-0.1644, -0.5151, -0.4716,  ..., -0.0843, -0.3432, -0.0742],\n",
      "        [ 0.3018,  0.1031,  0.4815,  ...,  0.3133, -0.2258,  0.4799]])), ('lstm.bias_ih_l0', tensor([-0.5454, -0.2439, -0.0140,  ..., -0.6296, -0.2638, -0.3654])), ('lstm.bias_hh_l0', tensor([-0.6008, -0.2762, -0.0129,  ..., -0.6467, -0.2473, -0.3139])), ('lstm.weight_ih_l1', tensor([[ 0.0099, -0.4869,  0.0045,  ..., -0.4432, -0.1337,  0.1016],\n",
      "        [ 0.1249, -0.8077, -0.2726,  ..., -0.0858, -0.0988,  0.5228],\n",
      "        [ 0.5105,  0.4352, -0.0971,  ...,  0.0123,  0.2328,  0.1023],\n",
      "        ...,\n",
      "        [ 0.0698, -0.2481, -0.0141,  ...,  0.8709,  0.3000,  0.2417],\n",
      "        [-0.0626,  0.5709, -0.3792,  ...,  0.1655, -0.6647,  0.4522],\n",
      "        [ 0.4294, -0.2150, -0.3751,  ...,  0.4538, -0.1586, -0.1396]])), ('lstm.weight_hh_l1', tensor([[ 0.3530, -0.2234, -0.7098,  ..., -0.4299, -0.1016, -0.8284],\n",
      "        [ 0.3693,  0.1902,  0.1064,  ..., -0.1422,  0.0973, -0.1519],\n",
      "        [-0.3099,  0.3002,  0.3396,  ...,  0.6189, -0.5427, -0.1202],\n",
      "        ...,\n",
      "        [-0.5070,  0.5455, -0.7723,  ...,  0.2931,  0.0296,  0.1965],\n",
      "        [-0.3319, -0.2963,  0.0023,  ..., -0.4141,  0.2793,  0.1321],\n",
      "        [ 0.5569,  0.0270, -0.3007,  ...,  0.2043, -0.1368, -0.6741]])), ('lstm.bias_ih_l1', tensor([-0.2241, -0.4531, -0.2396,  ..., -0.5451, -0.2821, -0.4781])), ('lstm.bias_hh_l1', tensor([-0.2130, -0.4894, -0.2843,  ..., -0.5736, -0.2603, -0.4208])), ('fc1.weight', tensor([[-0.1067, -0.1266, -0.0962,  ...,  0.2364,  0.3821, -0.1004],\n",
      "        [ 0.0487,  0.5301,  0.4585,  ..., -0.1013, -0.4044, -0.5114],\n",
      "        [ 0.0220,  0.5029, -0.2896,  ...,  0.5026, -0.0623,  0.6360],\n",
      "        ...,\n",
      "        [ 0.0833,  0.2261, -0.3461,  ..., -0.4251, -0.1172,  0.1352],\n",
      "        [ 0.1022,  0.3768,  0.4625,  ..., -0.3138,  0.3586, -0.1413],\n",
      "        [-0.0121, -0.0550, -0.3770,  ..., -0.1737,  0.3414,  0.1656]])), ('fc1.bias', tensor([-0.3446, -0.3697, -0.3150, -0.5996, -0.1960, -1.2458, -0.5553, -0.4990,\n",
      "         0.1021, -0.2229, -0.6474, -1.1443, -0.9859, -0.1021, -0.9923, -0.3894,\n",
      "        -0.2362, -0.0660, -0.8304, -0.9856, -0.7335, -0.3424, -0.5125, -0.3468,\n",
      "        -0.3046, -0.3628, -0.9939, -0.6299, -0.7011, -0.5969, -0.6924, -0.5537,\n",
      "        -0.3940, -0.9450, -0.5478, -0.3671, -0.7115, -0.6425, -0.4757, -0.2593,\n",
      "        -0.6551, -0.6104, -0.6276, -0.4052, -0.6067, -0.3871, -0.3224, -0.4517,\n",
      "        -0.5594, -0.6679, -0.4227, -0.0868, -0.3148, -0.4526, -0.4419, -0.4650,\n",
      "        -0.2920, -0.4563, -0.0278, -0.6123, -0.5932, -0.3762, -0.5102, -0.5038,\n",
      "        -0.2661, -0.4163, -0.0141, -0.2126, -0.7829, -0.5604, -0.7505, -0.5481,\n",
      "        -0.8498, -0.3842, -0.6623, -0.6553, -0.4945, -0.6285, -0.4918, -0.7578,\n",
      "        -0.3984, -0.5112, -0.0497, -0.5005, -0.3273, -0.4258, -0.1609, -0.1894,\n",
      "        -0.2730, -0.1223, -0.3539, -0.1462, -0.2603, -0.2274, -0.4309, -0.2548,\n",
      "        -0.7835, -0.1624, -0.4020, -0.2878, -0.6810, -0.3568, -0.2193, -0.7099,\n",
      "        -0.6788, -0.8466, -0.2527, -0.2676, -0.4865, -0.3352, -1.1117, -0.4850,\n",
      "        -0.9324, -1.0459,  0.2837,  0.1297, -0.9046, -0.4807, -0.9095, -0.5544,\n",
      "        -0.8789, -0.6488, -0.7308, -0.8884, -0.7152, -0.9077, -0.4732, -0.7344])), ('fc2.weight', tensor([[-2.7776, -1.3400, -0.8265,  ..., -0.8179, -0.5291, -1.5544],\n",
      "        [-4.4666, -0.2807, -1.1843,  ..., -1.7493,  0.1828, -5.2793],\n",
      "        [-1.2504, -1.4028, -0.9831,  ..., -0.4457, -1.0734, -0.0361],\n",
      "        ...,\n",
      "        [-0.2215, -0.3709, -1.2840,  ..., -1.9858, -0.4349, -0.2778],\n",
      "        [-2.5488, -1.1315, -0.4317,  ..., -0.4618, -1.0481, -0.6251],\n",
      "        [ 0.0219, -1.3346, -0.2197,  ..., -0.3361, -0.2030, -1.3468]])), ('fc2.bias', tensor([ 2.6617e-01,  8.5758e-01, -7.1439e-01,  4.5182e-01, -4.5564e-02,\n",
      "        -9.7990e-02,  6.4762e-01,  7.2251e-01, -2.1335e-01,  4.9279e-01,\n",
      "        -2.9517e-01, -4.8596e-01,  1.1275e-01,  2.6105e-01,  3.7928e-01,\n",
      "         3.4809e-02, -3.7490e-03, -5.3211e-01, -1.1491e-01, -8.9358e-02,\n",
      "         7.2278e-01, -2.8258e-01, -3.7167e-01,  5.4553e-01, -1.2842e-01,\n",
      "        -1.4812e-01,  7.1213e-01,  6.4556e-01, -3.5492e-01,  3.5587e-04,\n",
      "         3.2673e-02,  4.9837e-01, -1.9355e-02,  1.4808e-01,  4.1722e-02,\n",
      "        -1.7260e-01, -2.7390e-02, -4.4943e-01, -5.6216e-01, -2.9343e-01,\n",
      "         4.7102e-01,  5.0792e-01, -1.3690e-01, -1.7849e-01, -3.1395e-01,\n",
      "         6.7757e-02, -4.2516e-01, -4.6820e-01,  2.5764e-01, -4.4888e-01,\n",
      "        -2.3210e-01, -2.2990e-01, -5.8382e-01,  3.6934e-01,  5.8987e-01,\n",
      "        -1.8437e-01, -4.4364e-01,  6.8555e-02, -4.2682e-01,  2.1644e-01,\n",
      "         1.7342e-01, -2.0049e-01,  1.7471e-01,  1.8418e-01,  3.2782e-01,\n",
      "         1.7815e-01,  1.5095e-01, -5.8503e-01,  1.9062e-01, -5.2503e-02,\n",
      "         1.7278e-02, -6.2188e-02,  2.8349e-01,  1.8244e-01,  6.0298e-02,\n",
      "         2.9211e-01, -2.5579e-01,  1.3876e-01,  4.6090e-01,  6.2425e-02,\n",
      "        -1.2117e-01,  6.3191e-01, -3.8410e-01,  3.1815e-01,  1.8873e-01,\n",
      "         3.4974e-01,  2.2634e-01, -1.0438e-02, -2.1552e-01, -3.5232e-01,\n",
      "        -1.6160e-03,  5.3750e-01, -4.3729e-01, -9.3914e-02,  2.6296e-01,\n",
      "         2.1299e-01,  4.8678e-01, -2.9474e-01, -4.0660e-01, -2.4091e-01,\n",
      "        -1.7998e-01,  4.9984e-01, -8.0459e-02,  2.1877e-01,  1.0898e-01,\n",
      "        -8.9992e-02,  7.5739e-02,  3.3295e-01,  1.9019e-01,  3.9389e-01,\n",
      "        -3.1384e-02,  1.5896e-01,  1.5974e-01, -5.5799e-02,  3.3617e-01,\n",
      "         1.8552e-01, -7.5440e-02, -6.2557e-03,  4.9598e-01,  7.4685e-01,\n",
      "        -3.1254e-01,  1.4504e-01, -1.9650e-01, -3.2189e-01, -1.8103e-02,\n",
      "        -1.5057e-01, -4.7438e-01, -4.7391e-01,  6.4088e-02, -5.0464e-01,\n",
      "         5.1010e-01,  2.5745e-02, -3.5454e-02,  4.3762e-01,  5.3889e-01,\n",
      "        -9.0375e-02, -3.4712e-02,  2.1729e-01,  1.0016e-01, -2.9985e-01,\n",
      "         5.6606e-01,  3.6907e-01, -2.2346e-01, -4.8935e-02, -3.7395e-01,\n",
      "        -4.1492e-01, -7.8331e-02,  4.8753e-02,  1.5178e-01,  6.4665e-01,\n",
      "        -3.2742e-01, -5.1671e-02, -3.1533e-02,  1.0073e-01, -1.2288e-01,\n",
      "         4.7265e-02, -2.6310e-01, -2.6494e-01,  2.0938e-01, -5.0347e-01,\n",
      "        -6.0347e-01,  2.3301e-01, -3.2096e-01,  4.7542e-01,  2.3550e-01,\n",
      "        -4.6672e-01,  5.9759e-01,  2.2351e-01, -2.0359e-01, -5.3148e-01,\n",
      "        -2.7022e-01, -2.2420e-01, -5.6586e-01,  7.5694e-02, -2.8649e-01,\n",
      "         4.4708e-01, -3.2571e-02, -1.3945e-01,  7.0281e-01,  4.0220e-02,\n",
      "        -2.5585e-01,  4.1845e-01]))])\n"
     ]
    }
   ],
   "source": [
    "Net = torch.load('/home/admin1/Desktop/LSTM/state_dictionary/lstmmodel_basic.pth')\n",
    "print(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_classes, 100)\n",
    "        self.lstm = nn.LSTM(input_size=100, hidden_size=256, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the last timestep's output\n",
    "        x = self.fc1(lstm_out)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : \n",
      " correct predictions  : 9916 \n",
      " total predictions : 62712 \n",
      " Testing Accuracy : 15.81196581196581 \n",
      " ------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_classes = 182\n",
    "seq_length = 32\n",
    "\n",
    "model = LSTM(num_classes)  # Instantiate your model\n",
    "model.load_state_dict(torch.load('/home/admin1/Desktop/LSTM/state_dictionary/lstmmodel_basic.pth'))  # Load the state dictionary\n",
    "\n",
    "# Define testloader\n",
    "testloader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "\n",
    "    input , label = data\n",
    "    cumm_output = torch.zeros(0,len(unique_notes)).to(device)\n",
    "    cumm_label  = np.array([],dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        output = model(input.to(device))\n",
    "        cumm_output = torch.cat((cumm_output,output))\n",
    "        cumm_label = np.concatenate((cumm_label,label[:,k]))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output,1) == label[:,k].to(device))\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                               for ind,j in enumerate(input)])[:,1:]) \n",
    "test_acc =  float(correct_preds)/float(total_preds) *100 \n",
    "testreport =\"Testing Accuracy : \\n correct predictions  : {} \\n total predictions : {} \\n Testing Accuracy : {} \\n ------------------------\\n\".format(correct_preds,total_preds,test_acc)\n",
    "print(testreport)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working mostly better than the other one, hear the music0.mid file, it is not that bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_to_int(note):\n",
    "    # Dictionary mapping note names to MIDI numbers\n",
    "    note_dict = {\n",
    "        'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3, 'E': 4, 'F': 5,\n",
    "        'F#': 6, 'Gb': 6, 'G': 7, 'G#': 8, 'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, 'B': 11\n",
    "    }\n",
    "    if isinstance(note, str):  # if note is a string\n",
    "        if note.isdigit():  # if note is a number string\n",
    "            return int(note)\n",
    "        else:  # if note is a note string\n",
    "            # Separate the pitch and the octave (e.g. 'E5' -> ('E', '5'))\n",
    "            pitch, octave = note[:-1], note[-1]\n",
    "            # Replace '-' with 'b' in the pitch\n",
    "            pitch = pitch.replace('-', 'b')\n",
    "            # Calculate the MIDI number\n",
    "            midi_num = note_dict[pitch] + (int(octave) + 1) * 12\n",
    "            return midi_num\n",
    "    elif isinstance(note, int):  # if note is an integer\n",
    "        return note\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid note: {note}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "\n",
    "def convert_to_midi(prediction_output, path):\n",
    "    mid = mido.MidiFile()\n",
    "    track = mido.MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            for current_note in notes_in_chord:\n",
    "                cn = note_to_int(current_note)\n",
    "                # Create note_on and note_off events\n",
    "                track.append(mido.Message('note_on', note=cn, velocity=64, time=0))\n",
    "                track.append(mido.Message('note_off', note=cn, velocity=64, time=480))  # Assuming note length of 480 ticks\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            cn = note_to_int(pattern)\n",
    "            # Create note_on and note_off events\n",
    "            track.append(mido.Message('note_on', note=cn, velocity=64, time=0))\n",
    "            track.append(mido.Message('note_off', note=cn, velocity=64, time=480))  # Assuming note length of 480 ticks\n",
    "\n",
    "    mid.save(path)\n",
    "    print(f\"MIDI file saved at: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Taking the seed tune as follows:\n",
      "[162  47  11 162 160  11  76  97  99  17  99  97  50  92  46  50  76  97\n",
      "  99  17  99  65  97  65  50  65  92  50 159  97  99  17]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music0.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music0.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[ 17 145  42 145  92 145  42  46 145  56  17 145  42 145 116  37 145  42\n",
      " 145 120  89 170   8  50 170  58  89 170 159  50 170  39]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music1.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music1.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[ 18  58  44 100  58 165 124  58 123  47  15  89  58  37  17  58  11  42\n",
      "  58  50 170  71 171 172   8  50 170 171 172 165  50 170]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music2.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music2.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[ 17  47  70  99  47  79 100  47  37  47  37  47 129  37  47 100  47 130\n",
      "  28  47  41  28  47  41  28  47 100  47 129  37  47  79]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music3.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music3.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[ 15 162  89 108  15  37  61  99 169 162  87  21  38 156  46  76 144 162\n",
      " 144 172 162  55 162  11  76  99 162  11 169  37 145  15]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music4.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music4.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[113  16 147 104 113  69 147   9 113  35 104 149  35 110 113  67 149  80\n",
      " 113 122 149 168 113  87 147 102 117  87 160  59 100  75]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music5.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music5.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[142 180  98   2  97  24  76  89  91  46 180   2  91  21  47 142  21  16\n",
      "   2  46 113   2  46  16  76  22 180  98  47  22  98   2]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music6.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music6.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[180  34  34 180  44  91 180  34 136  34 136  43  33  98  14  43 177   2\n",
      " 180 177 117 180 135 139 180 168 113 180  14 142 180 168]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music7.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music7.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[139   2 162 162  27   2 162 171 171 162 171 126  98  78  68  27 166 166\n",
      " 110 124  35 110 102 102  74 110 102 122 122 102 122   2]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music8.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music8.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n",
      "Taking the seed tune as follows:\n",
      "[126 103   2  43  33   2  76  51  67 176 161  67  67  44  89 116 157  89\n",
      " 100  89 116 157  89  93 180  39  34 180 161 165  28  39]\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music9.midi\n",
      "MIDI file saved at: /home/admin1/Desktop/LSTM/Output2/music9.midi\n",
      "Failed to write MIDI file: Couldn't open timidity.cfg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pygame\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = model(input.to(device))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind])\n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = '/home/admin1/Desktop/LSTM/Output2/music' + str(j) + '.midi'\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    directory = os.path.dirname(path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Try to write the MIDI file\n",
    "    try:\n",
    "        convert_to_midi(tune, path)\n",
    "        print(f\"MIDI file saved at: {path}\")\n",
    "\n",
    "        # Load and play the MIDI file\n",
    "        pygame.mixer.music.load(path)\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.Clock().tick(10)  # Adjust playback speed if needed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write MIDI file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "\n",
    "# for j in range(10):\n",
    "#     index = random.randint(0,len(x_test))\n",
    "#     print(\"Taking the seed tune as follows:\")\n",
    "#     print(x_test[index])\n",
    "#     tune = x_test[index]\n",
    "#     input = np.empty((1,32),dtype=int)\n",
    "#     input[0] = tune\n",
    "#     input = torch.from_numpy(input)\n",
    "#     next_preds = 64\n",
    "#     for i in range(next_preds):\n",
    "#         #output = Net(input.to(device),input.shape[0])\n",
    "#         output = model(input.to(device))\n",
    "#         next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "#         input = input.cpu().detach().numpy()\n",
    "#         input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "#                                                    for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "#         tune = np.insert(tune,-1,next_preds[0])\n",
    "#     tune = [unique_notes[i] for i in tune]\n",
    "#     path = '/home/admin1/Desktop/LSTM/Output1/music'+str(j)+'.midi'\n",
    "    \n",
    "#     # Check if the directory exists, if not, create it\n",
    "#     directory = os.path.dirname(path)\n",
    "#     if not os.path.exists(directory):\n",
    "#         osimport os\n",
    "# import random\n",
    "\n",
    "# for j in range(10):\n",
    "#     index = random.randint(0,len(x_test))\n",
    "#     print(\"Taking the seed tune as follows:\")\n",
    "#     print(x_test[index])\n",
    "#     tune = x_test[index]\n",
    "#     input = np.empty((1,32),dtype=int)\n",
    "#     input[0] = tune\n",
    "#     input = torch.from_numpy(input)\n",
    "#     next_preds = 64\n",
    "#     for i in range(next_preds):\n",
    "#         #output = Net(input.to(device),input.shape[0])\n",
    "#         output = model(input.to(device))\n",
    "#         next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "#         iimport os\n",
    "# import random\n",
    "\n",
    "# for j in range(10):\n",
    "#     index = random.randint(0,len(x_test))\n",
    "#     print(\"Taking the seed tune as follows:\")\n",
    "#     print(x_test[index])\n",
    "#     tune = x_test[index]\n",
    "#     input = np.empty((1,32),dtype=int)\n",
    "#     input[0] = tune\n",
    "#     input = torch.from_numpy(input)\n",
    "#     next_preds = 64\n",
    "#     for i in range(next_preds):\n",
    "#         #output = Net(input.to(device),input.shape[0])\n",
    "#         output = model(input.to(device))\n",
    "#         next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "#         input = input.cpu().detach().numpy()\n",
    "#         input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "#                                                    for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "#         tune = np.insert(tune,-1,next_preds[0])\n",
    "#     tune = [unique_notes[i] for i in tune]\n",
    "#     path = '/home/admin1/Desktop/LSTM/Output1/music'+str(j)+'.midi'\n",
    "    \n",
    "#     # Check if the directory exists, if not, create it\n",
    "#     directory = os.path.dirname(path)\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "    \n",
    "#     # Try to write the MIDI file\n",
    "#     try:\n",
    "#         convert_to_midi(tune, path)\n",
    "#         print(f\"MIDI file saved at: {path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to write MIDI file: {e}\")nput = input.cpu().detach().numpy()\n",
    "#         input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "#                                                    for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "#         tune = np.insert(tune,-1,next_preds[0])\n",
    "#     tune = [unique_notes[i] for i in tune]\n",
    "#     path = '/home/admin1/Desktop/LSTM/Output1/music'+str(j)+'.midi'\n",
    "    \n",
    "#     # Check if the directory exists, if not, create it\n",
    "#     directory = os.path.dirname(path)\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "    \n",
    "#     # Try to write the MIDI file\n",
    "#     try:\n",
    "#         convert_to_midi(tune, path)\n",
    "#         print(f\"MIDI file saved at: {path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to write MIDI file: {e}\").makedirs(directory)\n",
    "    \n",
    "#     # Try to write the MIDI file\n",
    "#     try:\n",
    "#         convert_to_midi(tune, path)\n",
    "#         print(f\"MIDI file saved at: {path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to write MIDI file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
